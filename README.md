# You Found One Artifact. Here Are the Others.

This is the public work of Richard Porter (pen name) â€” a non-technical practitioner documenting what happens when humans collaborate with AI, and what goes wrong when nobodyâ€™s watching.

Everything here is free, voluntary, and given away. Nothing is sold. Nothing requires technical skill to use.

-----

## The Repositories

### ðŸ§Š [The Frozen Kernel](https://github.com/richard-porter/frozen-kernel)

**If you need the safety architecture.**
A session-level governance layer for human-AI collaboration. Set constraints before the session starts. The AI cannot negotiate its own boundaries. Includes the [Diagnostic Vocabulary](https://github.com/richard-porter/frozen-kernel/blob/main/diagnostic-vocabulary.md) â€” a glossary of named AI failure modes and human vulnerability patterns.

### ðŸ“– [AI Collaboration Field Guide](https://github.com/richard-porter/ai-collaboration-field-guide)

**If you need practical skills.**
How to see what AI is actually doing versus what it appears to be doing. Five learnable competencies identified through observed failure modes, the full diagnostic vocabulary in context, a starter kit with tools you can use immediately, and a replication challenge for independent testing.

### ðŸ”¬ [Dimensional Authorship](https://github.com/richard-porter/dimensional-authorship)

**If you want to see it in practice.**
The research home. Contains the Taller Shell Trilogy â€” a marine fantasy written through human-AI collaboration â€” plus the white paper documenting the origin event, escalation dynamics, governance intervention, and cross-model behavioral differentiation.

### ðŸ“Š [Adult Mode Safety Ledger](https://github.com/richard-porter/adult-mode-safety-ledger)

**If you need to measure.**
A public safety scorecard for high-gain AI conversational features. Binary architectural tests. Five AI models evaluated against the same criteria.

### ðŸ©º [Therapy Mode Safety Checklist](https://github.com/richard-porter/therapy-mode-safety-checklist.md)

**If it touches vulnerable humans.**
A six-question safety checklist for AI systems that interact with people in crisis. If it canâ€™t pass six questions, itâ€™s not ready.


### ðŸ“¡ [Trust Chain Protocol](https://github.com/richard-porter/richard-porter-trust-chain-protocol.git)

**If you need coordination safety for multi-agent systems.**

-----

## Where to Start

**If you use AI regularly** â†’ Read the [Diagnostic Vocabulary](https://github.com/richard-porter/frozen-kernel/blob/main/diagnostic-vocabulary.md). It names whatâ€™s happening to you.

**If youâ€™re building AI products** â†’ Read the [Field Guide](https://github.com/richard-porter/ai-collaboration-field-guide). It shows you what your users experience.

**If youâ€™re curious about the whole thing** â†’ Start with the [white paper](https://github.com/richard-porter/dimensional-authorship/blob/main/white-paper.md). Itâ€™s the documented story of one person figuring out how to work with AI without losing himself in the process.

-----

## About

All proceeds from published work support charitable organizations.

*The first step in sovereignty is naming whatâ€™s happening to you. The second step is deciding what to do about it. There is no third step.*

## Suggested GitHub Topics

`ai-safety` Â· `ai-psychosis` Â· `ai-governance` Â· `llm-safety` Â· `sycophancy` Â· `ai-alignment` Â· `behavioral-safety` Â· `deterministic-safety` Â· `human-ai-interaction` Â· `ai-ethics` Â· `mental-health` Â· `ai-accountability` Â· `guardrails` Â· `responsible-ai`
